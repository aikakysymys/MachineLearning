{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB! Несколько важных советов для этого задания дала Анна Николаева."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16406"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv('train.csv',sep = '\\t', quoting=csv.QUOTE_NONE,encoding='utf-8').fillna(0)\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.rename(index=str, columns={\"class\": \"class_\"}, inplace=True,) # inplace=True means the df is really changed\n",
    "#train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev = pd.read_csv('dev.csv',sep = '\\t', quoting=csv.QUOTE_NONE).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv',sep = '\\t', quoting=csv.QUOTE_NONE).fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the sentences for our own model training\n",
    "all_text = train['text'].tolist() + dev['text'].tolist() + test['text'].tolist()\n",
    "\n",
    "#train_dev_labels1 = train['class_'].tolist() + dev['class_'].tolist()\n",
    "\n",
    "# make a file with all sents\n",
    "with open('./all_sents.txt', 'w') as f: \n",
    "    for sent in all_text:\n",
    "     #   text = lemmatize_source(text)\n",
    "        f.write(sent + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get train sentences in one text for normalizing\n",
    "tr_text = \"tyxz \".join(train['text'].tolist())\n",
    "#len(tr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dev sentences in one text for normalizing\n",
    "dev_text = \"tyxz \".join(dev['text'].tolist())\n",
    "#len(dev_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get test sentences in one text for normalizing\n",
    "test_text = test['text'].tolist()\n",
    "test_text_j = \"\\n\".join(test_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'A': 'ADJ', 'ADV': 'ADV', 'ADVPRO': 'ADV', 'ANUM': 'ADJ', 'APRO': 'DET', 'COM': 'ADJ', 'CONJ': 'SCONJ', 'INTJ': 'INTJ', 'NONLEX': 'X', 'NUM': 'NUM', 'PART': 'PART', 'PR': 'ADP', 'S': 'NOUN', 'SPRO': 'PRON', 'UNKN': 'X', 'V': 'VERB'}\n"
     ]
    }
   ],
   "source": [
    "# change postags in case we try an external model\n",
    "\n",
    "import requests\n",
    "import re\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/akutuzov/universal-pos-tags/4653e8a9154e93fe2f417c7fdb7a357b7d6ce333/ru-rnc.map'\n",
    "\n",
    "mapping = {}\n",
    "r = requests.get(url, stream=True)\n",
    "for pair in r.text.split('\\n'):\n",
    "    pair = re.sub('\\s+', ' ', pair, flags=re.U).split(' ')\n",
    "    if len(pair) > 1:\n",
    "        mapping[pair[0]] = pair[1]\n",
    "\n",
    "print(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lemmas with postags\n",
    "\n",
    "from pymystem3 import Mystem\n",
    "\n",
    "punct = '!\"#$%&\\'()*+\\./:;<=>?@[]^_`{|}~«»…“”*№,–-0123456789'\n",
    "m = Mystem()\n",
    "#MAX_length = 50\n",
    "\n",
    "def tag_mystem(text='Текст нужно передать функции в виде строки!'):  \n",
    "  #  m = Mystem()\n",
    "    processed = m.analyze(text)\n",
    "    lem_tag_d = {}\n",
    "    tagged = []\n",
    "    count = 0\n",
    "    \n",
    "    for w in processed:\n",
    "        count += 1\n",
    "        try:\n",
    "            lemma = w[\"analysis\"][0][\"lex\"].lower().strip()\n",
    "            pos = w[\"analysis\"][0][\"gr\"].split(',')[0]\n",
    "            pos = pos.split('=')[0].strip()\n",
    "            if pos in mapping:\n",
    "                tagged.append(lemma + '_' + mapping[pos]) # здесь мы конвертируем тэги\n",
    "            else:\n",
    "                    tagged.append(lemma + '_X') # на случай, если попадется тэг, которого нет в маппинге\n",
    "        except (IndexError, KeyError):\n",
    "            word = w[\"text\"].lower()\n",
    "            tagged.append(word) \n",
    "\n",
    "    return ' '.join(tagged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take text input for mystem\n",
    "\n",
    "all_sents = ''\n",
    "\n",
    "with open('./all_sents.txt', 'r') as f:\n",
    "    line = f.readlines()\n",
    "    for sent in all_text:\n",
    "        all_sents += sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all sents are lemmatized with postags like this\n",
    "\n",
    "with open('./all_lem_sents1.txt', 'w') as f:\n",
    "        tagged_lemmas = tag_mystem(all_sents)\n",
    "        f.write(tagged_lemmas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a model of word2vec vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-11 20:57:48,201:WARNING:consider setting layer size to a multiple of 4 for greater performance\n",
      "2019-05-11 20:57:48,230:INFO:collecting all words and their counts\n",
      "2019-05-11 20:57:48,411:INFO:PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2019-05-11 20:57:48,782:INFO:collected 48496 word types from a corpus of 573022 raw words and 58 sentences\n",
      "2019-05-11 20:57:48,794:INFO:Loading a fresh vocabulary\n",
      "2019-05-11 20:57:50,996:INFO:effective_min_count=2 retains 19178 unique words (39% of original 48496, drops 29318)\n",
      "2019-05-11 20:57:50,997:INFO:effective_min_count=2 leaves 543704 word corpus (94% of original 573022, drops 29318)\n",
      "2019-05-11 20:57:51,111:INFO:deleting the raw counts dictionary of 48496 items\n",
      "2019-05-11 20:57:51,116:INFO:sample=0.001 downsamples 31 most-common words\n",
      "2019-05-11 20:57:51,127:INFO:downsampling leaves estimated 422215 word corpus (77.7% of prior 543704)\n",
      "2019-05-11 20:57:51,232:INFO:estimated required memory for 19178 words and 30 dimensions: 14191720 bytes\n",
      "2019-05-11 20:57:51,234:INFO:resetting layer weights\n",
      "2019-05-11 20:57:51,535:INFO:training model with 3 workers on 19178 vocabulary and 30 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2019-05-11 20:57:52,383:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-11 20:57:52,401:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-11 20:57:52,403:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-11 20:57:52,403:INFO:EPOCH - 1 : training on 573022 raw words (422320 effective words) took 0.8s, 506922 effective words/s\n",
      "2019-05-11 20:57:53,261:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-11 20:57:53,268:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-11 20:57:53,273:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-11 20:57:53,274:INFO:EPOCH - 2 : training on 573022 raw words (421842 effective words) took 0.9s, 493816 effective words/s\n",
      "2019-05-11 20:57:54,052:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-11 20:57:54,058:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-11 20:57:54,060:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-11 20:57:54,061:INFO:EPOCH - 3 : training on 573022 raw words (422042 effective words) took 0.8s, 539611 effective words/s\n",
      "2019-05-11 20:57:54,858:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-11 20:57:54,861:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-11 20:57:54,867:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-11 20:57:54,868:INFO:EPOCH - 4 : training on 573022 raw words (422282 effective words) took 0.8s, 525795 effective words/s\n",
      "2019-05-11 20:57:55,670:INFO:worker thread finished; awaiting finish of 2 more threads\n",
      "2019-05-11 20:57:55,682:INFO:worker thread finished; awaiting finish of 1 more threads\n",
      "2019-05-11 20:57:55,684:INFO:worker thread finished; awaiting finish of 0 more threads\n",
      "2019-05-11 20:57:55,685:INFO:EPOCH - 5 : training on 573022 raw words (422045 effective words) took 0.8s, 521376 effective words/s\n",
      "2019-05-11 20:57:55,686:INFO:training on a 2865110 raw words (2110531 effective words) took 4.2s, 508555 effective words/s\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(format='%(asctime)s:%(levelname)s:%(message)s',level=logging.INFO)\n",
    "                    \n",
    "data = gensim.models.word2vec.LineSentence(\"all_lem_sents1.txt\")\n",
    "gen_model_tagged = gensim.models.Word2Vec(data, size=30, window=10,min_count=2,sg=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-11 20:58:04,214:INFO:saving Word2Vec object under CBOW_30_10_new.model, separately None\n",
      "2019-05-11 20:58:04,216:INFO:not storing attribute vectors_norm\n",
      "2019-05-11 20:58:04,229:INFO:not storing attribute cum_table\n",
      "2019-05-11 20:58:04,395:INFO:saved CBOW_30_10_new.model\n"
     ]
    }
   ],
   "source": [
    "gen_model_tagged.save('CBOW_30_10_new.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare lemmatised test and train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test lemmas made\n",
    "test_tagged_lemmas = tag_mystem(test_text_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tagged_lemmas_ = test_tagged_lemmas.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "588823"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del test_tagged_lemmas_[-1]\n",
    "len(test_tagged_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2045"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_text_j.split(\"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Изобретение относится к судостроению и касаетс...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Эти состояния называют фазами воды, а превраще...</td>\n",
       "      <td>1</td>\n",
       "      <td>14:22</td>\n",
       "      <td>0:13</td>\n",
       "      <td>23:34</td>\n",
       "      <td>81:81</td>\n",
       "      <td>38:78</td>\n",
       "      <td>81:100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>И должен ни единой долькой  Не отступаться от ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Он потребовал обеспечить полное осуществление ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>По мнению местного пастора Элла Эбанкса, запре...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class     cV   cR1  \\\n",
       "0  Изобретение относится к судостроению и касаетс...      0      0     0   \n",
       "1  Эти состояния называют фазами воды, а превраще...      1  14:22  0:13   \n",
       "2  И должен ни единой долькой  Не отступаться от ...      0      0     0   \n",
       "3  Он потребовал обеспечить полное осуществление ...      0      0     0   \n",
       "4  По мнению местного пастора Элла Эбанкса, запре...      0      0     0   \n",
       "\n",
       "     cR2      V     R1      R2  \n",
       "0      0      0      0       0  \n",
       "1  23:34  81:81  38:78  81:100  \n",
       "2      0      0      0       0  \n",
       "3      0      0      0       0  \n",
       "4      0      0      0       0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' и_SCONJ   должный_ADJ   ни_PART   единый_ADJ   долька_NOUN    не_PART   отступаться_VERB   от_ADP   лицо_NOUN ,   но_SCONJ   быть_VERB   живой_ADJ ,  живой_ADJ   и_SCONJ   только_PART ,   живой_ADJ   и_SCONJ   только_PART   до_ADP   конец_NOUN . '"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['text'][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>изобретение_NOUN   относиться_VERB   к_ADP   с...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>этот_DET   состояние_NOUN   называть_VERB   ф...</td>\n",
       "      <td>1</td>\n",
       "      <td>14:22</td>\n",
       "      <td>0:13</td>\n",
       "      <td>23:34</td>\n",
       "      <td>81:81</td>\n",
       "      <td>38:78</td>\n",
       "      <td>81:100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>и_SCONJ   должный_ADJ   ни_PART   единый_ADJ ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>он_PRON   потребовать_VERB   обеспечивать_VER...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>по_ADP   мнение_NOUN   местный_ADJ   пастор_N...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class     cV   cR1  \\\n",
       "0  изобретение_NOUN   относиться_VERB   к_ADP   с...      0      0     0   \n",
       "1   этот_DET   состояние_NOUN   называть_VERB   ф...      1  14:22  0:13   \n",
       "2   и_SCONJ   должный_ADJ   ни_PART   единый_ADJ ...      0      0     0   \n",
       "3   он_PRON   потребовать_VERB   обеспечивать_VER...      0      0     0   \n",
       "4   по_ADP   мнение_NOUN   местный_ADJ   пастор_N...      0      0     0   \n",
       "\n",
       "     cR2      V     R1      R2  \n",
       "0      0      0      0       0  \n",
       "1  23:34  81:81  38:78  81:100  \n",
       "2      0      0      0       0  \n",
       "3      0      0      0       0  \n",
       "4      0      0      0       0  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make a df with lemmas\n",
    "test_lem = test\n",
    "test_lem.drop([\"text\"], axis=1, inplace=True)\n",
    "test_lem.insert(0, \"text\", test_tagged_lemmas_, True)\n",
    "test_lem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' широкий_ADJ   и_SCONJ   тяжелый_ADJ   кисть_NOUN   их_DET   длинный_ADJ   рука_NOUN   походить_VERB   на_ADP   лопата_NOUN ,  а_SCONJ   голова_NOUN  –  на_ADP   таран_NOUN . '"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_lem['text'][45]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_lemmas = test_lem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new df\n",
    "test_lem.to_csv(r'test_lemmas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train lemmas made\n",
    "tr_tagged_lemmas = tag_mystem(tr_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used \"tyxz\" instead of \"\\n\" in tag_mystem to avoid an extra sentence\n",
    "tr_tagged_lemmas_ = tr_tagged_lemmas.split(\"tyxz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16406"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_tagged_lemmas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16406"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tr_text.split(\"tyxz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16406"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Выворачивает наизнанку, запад превращает в юг, а север — в восток, меняет местами добро и зло, велит открыть своё сердце, ничего не требуя взамен.'"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['text'][5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>быть_VERB   в_ADP   прошлый_ADJ   четверг_NOUN...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>работа_NOUN   с_ADP   двухбайтовый_ADJ   на...</td>\n",
       "      <td>1</td>\n",
       "      <td>92:99</td>\n",
       "      <td>83:91</td>\n",
       "      <td>103:109</td>\n",
       "      <td>127:127</td>\n",
       "      <td>119:124</td>\n",
       "      <td>127:134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>заместитель_NOUN   генеральный_ADJ   секрет...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>продажа_NOUN   недвижимость_NOUN   из_ADP  ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>новый_ADJ   являться_VERB   то_SCONJ ,  что...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class     cV    cR1  \\\n",
       "0  быть_VERB   в_ADP   прошлый_ADJ   четверг_NOUN...      0      0      0   \n",
       "1     работа_NOUN   с_ADP   двухбайтовый_ADJ   на...      1  92:99  83:91   \n",
       "2     заместитель_NOUN   генеральный_ADJ   секрет...      0      0      0   \n",
       "3     продажа_NOUN   недвижимость_NOUN   из_ADP  ...      0      0      0   \n",
       "4     новый_ADJ   являться_VERB   то_SCONJ ,  что...      0      0      0   \n",
       "\n",
       "       cR2        V       R1       R2  \n",
       "0        0        0        0        0  \n",
       "1  103:109  127:127  119:124  127:134  \n",
       "2        0        0        0        0  \n",
       "3        0        0        0        0  \n",
       "4        0        0        0        0  "
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make a df with lemmas\n",
    "train_lem = train\n",
    "train_lem.drop([\"text\"], axis=1, inplace=True)\n",
    "train_lem.insert(0, \"text\", tr_tagged_lemmas_, True)\n",
    "train_lem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   специалист_NOUN   отмечать_VERB  « грамотный_ADJ   подход_NOUN   к_ADP   ландшафт_NOUN »,  но_SCONJ   рекомендовать_VERB   более_ADV   тщательно_ADV   продумывать_VERB   пляжный_ADJ   зона_NOUN ,  где_ADV   быть_VERB   отдыхать_VERB   не_PART   только_PART   турист_NOUN   из_ADP   отель_NOUN ,  но_SCONJ   и_SCONJ   местный_ADJ   жители'"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lem['text'][6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new df\n",
    "train_lem.to_csv(r'train_lemmas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dev lemmas made\n",
    "dev_tagged_lemmas = tag_mystem(dev_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "# used \"tyxz\" instead of \"\\n\" in tag_mystem to avoid an extra sentence\n",
    "dev_tagged_lemmas_ = dev_tagged_lemmas.split(\"tyxz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4142"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dev_tagged_lemmas_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'центральный_ADJ   часть_NOUN   лунный_ADJ   тень_NOUN ,  где_ADV   наблюдаться_VERB   полный_ADJ   фаза_NOUN   затмение_NOUN   вступать_VERB   на_ADP   земля_NOUN   в_ADP   атлантика_NOUN ,  пересекать_VERB   южный_ADJ   часть_NOUN   африканский_ADJ   континент_NOUN   и_SCONJ   крупный_ADJ   остров_NOUN   мадагаскар_NOUN ,  а_SCONJ   завершать_VERB   свой_DET   путь_NOUN   на_ADP   закат_NOUN   в_ADP   индийский_ADJ   океане'"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_tagged_lemmas_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>центральный_ADJ   часть_NOUN   лунный_ADJ   те...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>я_PRON   превращать_VERB   твой_DET   сердц...</td>\n",
       "      <td>1</td>\n",
       "      <td>2:10</td>\n",
       "      <td>11:22</td>\n",
       "      <td>23:30</td>\n",
       "      <td>54:54</td>\n",
       "      <td>34:52</td>\n",
       "      <td>54:60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>в_ADP   данный_ADJ   пример_NOUN   строка_N...</td>\n",
       "      <td>1</td>\n",
       "      <td>24:37</td>\n",
       "      <td>17:23</td>\n",
       "      <td>38:56</td>\n",
       "      <td>68:68</td>\n",
       "      <td>60:67</td>\n",
       "      <td>68:88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ассоциация_NOUN   намерен_ADJ   занимать_VE...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" ты_PRON   сам_DET   весь_DET   портить_VER...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class     cV    cR1  \\\n",
       "0  центральный_ADJ   часть_NOUN   лунный_ADJ   те...      0      0      0   \n",
       "1     я_PRON   превращать_VERB   твой_DET   сердц...      1   2:10  11:22   \n",
       "2     в_ADP   данный_ADJ   пример_NOUN   строка_N...      1  24:37  17:23   \n",
       "3     ассоциация_NOUN   намерен_ADJ   занимать_VE...      0      0      0   \n",
       "4    \" ты_PRON   сам_DET   весь_DET   портить_VER...      0      0      0   \n",
       "\n",
       "     cR2      V     R1     R2  \n",
       "0      0      0      0      0  \n",
       "1  23:30  54:54  34:52  54:60  \n",
       "2  38:56  68:68  60:67  68:88  \n",
       "3      0      0      0      0  \n",
       "4      0      0      0      0  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's make a df with lemmas\n",
    "dev_lem = dev\n",
    "dev_lem.drop([\"text\"], axis=1, inplace=True)\n",
    "dev_lem.insert(0, \"text\", dev_tagged_lemmas_, True)\n",
    "dev_lem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'центральный_ADJ   часть_NOUN   лунный_ADJ   тень_NOUN ,  где_ADV   наблюдаться_VERB   полный_ADJ   фаза_NOUN   затмение_NOUN   вступать_VERB   на_ADP   земля_NOUN   в_ADP   атлантика_NOUN ,  пересекать_VERB   южный_ADJ   часть_NOUN   африканский_ADJ   континент_NOUN   и_SCONJ   крупный_ADJ   остров_NOUN   мадагаскар_NOUN ,  а_SCONJ   завершать_VERB   свой_DET   путь_NOUN   на_ADP   закат_NOUN   в_ADP   индийский_ADJ   океане'"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_lem['text'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make one df for train and dev\n",
    "train_lemmas = pd.concat([dev_lem, train_lem], ignore_index=True, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20548"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>class</th>\n",
       "      <th>cV</th>\n",
       "      <th>cR1</th>\n",
       "      <th>cR2</th>\n",
       "      <th>V</th>\n",
       "      <th>R1</th>\n",
       "      <th>R2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>центральный_ADJ   часть_NOUN   лунный_ADJ   те...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>я_PRON   превращать_VERB   твой_DET   сердц...</td>\n",
       "      <td>1</td>\n",
       "      <td>2:10</td>\n",
       "      <td>11:22</td>\n",
       "      <td>23:30</td>\n",
       "      <td>54:54</td>\n",
       "      <td>34:52</td>\n",
       "      <td>54:60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>в_ADP   данный_ADJ   пример_NOUN   строка_N...</td>\n",
       "      <td>1</td>\n",
       "      <td>24:37</td>\n",
       "      <td>17:23</td>\n",
       "      <td>38:56</td>\n",
       "      <td>68:68</td>\n",
       "      <td>60:67</td>\n",
       "      <td>68:88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ассоциация_NOUN   намерен_ADJ   занимать_VE...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\" ты_PRON   сам_DET   весь_DET   портить_VER...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  class     cV    cR1  \\\n",
       "0  центральный_ADJ   часть_NOUN   лунный_ADJ   те...      0      0      0   \n",
       "1     я_PRON   превращать_VERB   твой_DET   сердц...      1   2:10  11:22   \n",
       "2     в_ADP   данный_ADJ   пример_NOUN   строка_N...      1  24:37  17:23   \n",
       "3     ассоциация_NOUN   намерен_ADJ   занимать_VE...      0      0      0   \n",
       "4    \" ты_PRON   сам_DET   весь_DET   портить_VER...      0      0      0   \n",
       "\n",
       "     cR2      V     R1     R2  \n",
       "0      0      0      0      0  \n",
       "1  23:30  54:54  34:52  54:60  \n",
       "2  38:56  68:68  60:67  68:88  \n",
       "3      0      0      0      0  \n",
       "4      0      0      0      0  "
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_lemmas.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the new train df\n",
    "train_lemmas.to_csv(r'train_dev_lemmas.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the w2v model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2019-05-11 20:58:20,601:INFO:loading Word2Vec object from CBOW_30_10_new.model\n",
      "2019-05-11 20:58:20,731:INFO:loading wv recursively from CBOW_30_10_new.model.wv.* with mmap=None\n",
      "2019-05-11 20:58:20,733:INFO:setting ignored attribute vectors_norm to None\n",
      "2019-05-11 20:58:20,734:INFO:loading vocabulary recursively from CBOW_30_10_new.model.vocabulary.* with mmap=None\n",
      "2019-05-11 20:58:20,736:INFO:loading trainables recursively from CBOW_30_10_new.model.trainables.* with mmap=None\n",
      "2019-05-11 20:58:20,737:INFO:setting ignored attribute cum_table to None\n",
      "2019-05-11 20:58:20,738:INFO:loaded CBOW_30_10_new.model\n",
      "2019-05-11 20:58:20,821:INFO:precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8693796\n"
     ]
    }
   ],
   "source": [
    "gen_model_tagged=gensim.models.Word2Vec.load('CBOW_30_10_new.model')\n",
    "gen_model_tagged.init_sims(replace=True)\n",
    "print(gen_model_tagged.wv.similarity('центральный_ADJ', 'часть_NOUN'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.34299147\n"
     ]
    }
   ],
   "source": [
    "print(gen_model_tagged.wv.similarity('в_ADP', 'сердце_NOUN'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data for a bi model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import array #\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "import keras_metrics as km\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first filter out too long sents \n",
    "MAX_length = 60 # words\n",
    "\n",
    "def filter(df, MAX_length):\n",
    "    docs = []\n",
    "    labels = []\n",
    "    text_index = []\n",
    "    for i in range(len(df)):        \n",
    "        sent = ' ' + df['text'][i]       \n",
    "        if len(sent.split()) <= MAX_length:\n",
    "            docs.append(sent)\n",
    "            labels.append(df['class'][i])\n",
    "         #   print(labels)\n",
    "            text_index.append(i)\n",
    "    labels = array(labels)\n",
    "    return docs, labels, text_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_test\n",
    "docs_train, labels_train, text_index = filter(train_lemmas, MAX_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19874"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#docs_test\n",
    "docs_test, labels_test, test_text_index = filter(test_lemmas, MAX_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2045"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_lemmas['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1992"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  и_SCONJ   должный_ADJ   ни_PART   единый_ADJ   долька_NOUN    не_PART   отступаться_VERB   от_ADP   лицо_NOUN ,   но_SCONJ   быть_VERB   живой_ADJ ,  живой_ADJ   и_SCONJ   только_PART ,   живой_ADJ   и_SCONJ   только_PART   до_ADP   конец_NOUN . '"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_test[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'    в_ADP   данный_ADJ   пример_NOUN   строка_NOUN   сгруппировывать_VERB   по_ADP   название_NOUN   товар_NOUN ,  а_SCONJ   столбец_NOUN   по_ADP   категория_NOUN   товар_NOUN . '"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vector(sent, model):\n",
    "    matrix = np.zeros((60,30)) # 60 words, 50 dimentions for a word in the model\n",
    "    for i, lemma in enumerate(sent.split()):\n",
    "       # print(lemma)\n",
    "        if lemma in model.wv:\n",
    "           # print('in model', model.wv[lemma], 'old',  model[lemma])\n",
    "            vec = model.wv[lemma]\n",
    "         #   print(vec)\n",
    "            matrix[i] = vec\n",
    "            \n",
    "        else:\n",
    "            pass\n",
    "   # print(matrix)\n",
    "    vector = np.concatenate(matrix)\n",
    "   # print(vector, len(vector))\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' сущность   изобретение_NOUN :  в_ADP   ранорасширитель_NOUN   вводить_VERB   съемный_ADJ   цилиндрический_ADJ   дренировать_VERB   эластичный_ADJ   оболочка_NOUN ,  а_SCONJ   сам_DET   ранорасширитель_NOUN   выполнять_VERB   в_ADP   вид_NOUN   тороидальный_ADJ   зигзагообразный_ADJ   элемент_NOUN   из_ADP   материал_NOUN   с_ADP   эффект_NOUN   память_NOUN   формы'"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_train[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for train\n",
    "\n",
    "train_vec = []\n",
    "for i in range(len(docs_train)):\n",
    "    sent_vec = get_vector(docs_train[i], gen_model_tagged)\n",
    "    train_vec.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.02435374, -0.16665716,  0.03422824, ...,  0.        ,\n",
       "        0.        ,  0.        ])"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_vec[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectors for test\n",
    "\n",
    "test_vec = []\n",
    "for i in range(len(docs_test)):\n",
    "    sent_vec = get_vector(docs_test[i], gen_model_tagged)\n",
    "    test_vec.append(sent_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.18666001 -0.24182636 -0.03915953 ...  0.          0.\n",
      "  0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(test_vec[9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 300)               540300    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 300)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 200)               60200     \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 200)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 600,701\n",
      "Trainable params: 600,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(300, input_dim=1800))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(200))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc', km.binary_precision(), km.binary_recall()])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.stack(train_vec, axis=0) # to make data readable for Keras\n",
    "x_test = np.stack(test_vec, axis=0)\n",
    "y_train = np.asarray(labels_train)\n",
    "y_test = np.asarray(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight  # to balance the classes\n",
    "\n",
    "class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                 np.unique(y_train),\n",
    "                                                 y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19874 samples, validate on 1992 samples\n",
      "Epoch 1/10\n",
      "19874/19874 [==============================] - 9s 450us/step - loss: 0.2814 - acc: 0.8794 - precision: 0.8382 - recall: 0.8060 - val_loss: 0.4276 - val_acc: 0.8128 - val_precision: 0.7187 - val_recall: 0.7284\n",
      "Epoch 2/10\n",
      "19874/19874 [==============================] - 8s 409us/step - loss: 0.2629 - acc: 0.8865 - precision: 0.8432 - recall: 0.8243 - val_loss: 0.4574 - val_acc: 0.8052 - val_precision: 0.7032 - val_recall: 0.7284\n",
      "Epoch 3/10\n",
      "19874/19874 [==============================] - 8s 408us/step - loss: 0.2481 - acc: 0.8948 - precision: 0.8583 - recall: 0.8327 - val_loss: 0.4731 - val_acc: 0.8163 - val_precision: 0.7197 - val_recall: 0.7433\n",
      "Epoch 4/10\n",
      "19874/19874 [==============================] - 8s 412us/step - loss: 0.2298 - acc: 0.9058 - precision: 0.8716 - recall: 0.8524 - val_loss: 0.4960 - val_acc: 0.7977 - val_precision: 0.6836 - val_recall: 0.7418\n",
      "Epoch 5/10\n",
      "19874/19874 [==============================] - 9s 432us/step - loss: 0.2124 - acc: 0.9127 - precision: 0.8808 - recall: 0.8639 - val_loss: 0.5149 - val_acc: 0.8082 - val_precision: 0.7075 - val_recall: 0.7328\n",
      "Epoch 6/10\n",
      "19874/19874 [==============================] - 8s 410us/step - loss: 0.2037 - acc: 0.9161 - precision: 0.8864 - recall: 0.8680 - val_loss: 0.4944 - val_acc: 0.8112 - val_precision: 0.7162 - val_recall: 0.7269\n",
      "Epoch 7/10\n",
      "19874/19874 [==============================] - 8s 408us/step - loss: 0.1908 - acc: 0.9222 - precision: 0.8956 - recall: 0.8766 - val_loss: 0.5025 - val_acc: 0.8077 - val_precision: 0.7077 - val_recall: 0.7299\n",
      "Epoch 8/10\n",
      "19874/19874 [==============================] - 8s 414us/step - loss: 0.1800 - acc: 0.9276 - precision: 0.9024 - recall: 0.8861 - val_loss: 0.5714 - val_acc: 0.7877 - val_precision: 0.6573 - val_recall: 0.7701\n",
      "Epoch 9/10\n",
      "19874/19874 [==============================] - 8s 423us/step - loss: 0.1689 - acc: 0.9316 - precision: 0.9085 - recall: 0.8916 - val_loss: 0.5698 - val_acc: 0.7987 - val_precision: 0.6871 - val_recall: 0.7373\n",
      "Epoch 10/10\n",
      "19874/19874 [==============================] - 8s 425us/step - loss: 0.1606 - acc: 0.9354 - precision: 0.9146 - recall: 0.8965 - val_loss: 0.5561 - val_acc: 0.8047 - val_precision: 0.7051 - val_recall: 0.7209\n"
     ]
    }
   ],
   "source": [
    "results = model.fit(\n",
    "    x_train, y_train,\n",
    "    epochs = 10,\n",
    "    batch_size = 50,\n",
    "    validation_data = (x_test, y_test),\n",
    "    class_weight = class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1992/1992 [==============================] - 0s 107us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7516283683792009"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "score[1] * score[2] * 2 / (score[1] + score[2]) #\n",
    "# получаем такую F-меру"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('gap_model.h5')  \n",
    "\n",
    "#del model  # deletes the existing model\n",
    "\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "#model = load_model('gap_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Оценка результатов бинарной классификации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a prediction\n",
    "prediction = model.predict(x_test)\n",
    "predi_cate = []\n",
    "for i in prediction:\n",
    "    if i < 0.5:\n",
    "        predi_cate.append(0)\n",
    "    else:\n",
    "        predi_cate.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 0, 0, 0]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predi_cate[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare csv-s for agrr_metrics.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeros = []\n",
    "for i in enumerate(docs_test):\n",
    "    zeros.append('0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig = pd.DataFrame({'text': docs_test, 'class_': labels_test, 'cV':zeros, 'cR1':zeros, 'cR2':zeros, 'V':zeros, 'R1':zeros, 'R2':zeros})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_orig.to_csv(r'test_orig.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred = pd.DataFrame({'text': docs_test, 'class_': predi_cate, 'cV':zeros, 'cR1':zeros, 'cR2':zeros, 'V':zeros, 'R1':zeros, 'R2':zeros})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred.to_csv(r'test_pred.csv', sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary classification quality (f1-score): 0.7129151291512915\r\n",
      "Other metrics: \r\n",
      " Precision: 0.7051094890510949\r\n",
      " Recall: 0.7208955223880597\r\n"
     ]
    }
   ],
   "source": [
    "! python3 agrr_metrics.py -b test_orig.csv test_pred.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the result is much better than with one-hot embeddings without pos-tagging, or any other symbols but Russian letters, as in the first run. It is predictable, as gapping is definitely connected with pos and punctuation, and sometimes numbers are also helpful, as they can be cR1/2 or R1/2, so the model could learn meaningful features. Also, three layers instaed of 1 make sense, and around 10 epochs are enough to train such a binary model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
